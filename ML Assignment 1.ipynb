{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60b8566e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa0dfd36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CustomerID  Age  Gender  Tenure  Usage Frequency  Support Calls  \\\n",
      "0           1   22  Female      25               14              4   \n",
      "1           2   41  Female      28               28              7   \n",
      "2           3   47    Male      27               10              2   \n",
      "3           4   35    Male       9               12              5   \n",
      "4           5   53  Female      58               24              9   \n",
      "\n",
      "   Payment Delay Subscription Type Contract Length  Total Spend  \\\n",
      "0             27             Basic         Monthly          598   \n",
      "1             13          Standard         Monthly          584   \n",
      "2             29           Premium          Annual          757   \n",
      "3             17           Premium       Quarterly          232   \n",
      "4              2          Standard          Annual          533   \n",
      "\n",
      "   Last Interaction  Churn  \n",
      "0                 9      1  \n",
      "1                20      0  \n",
      "2                21      0  \n",
      "3                18      0  \n",
      "4                18      0  \n"
     ]
    }
   ],
   "source": [
    "# Specify the file path\n",
    "file_path = r'C:\\Users\\AKSHITHA\\Downloads\\customer_churn_dataset-testing-master.csv\\customer_churn_dataset-testing-master.csv'\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a735e1b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 64374 entries, 0 to 64373\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   CustomerID         64374 non-null  int64 \n",
      " 1   Age                64374 non-null  int64 \n",
      " 2   Gender             64374 non-null  object\n",
      " 3   Tenure             64374 non-null  int64 \n",
      " 4   Usage Frequency    64374 non-null  int64 \n",
      " 5   Support Calls      64374 non-null  int64 \n",
      " 6   Payment Delay      64374 non-null  int64 \n",
      " 7   Subscription Type  64374 non-null  object\n",
      " 8   Contract Length    64374 non-null  object\n",
      " 9   Total Spend        64374 non-null  int64 \n",
      " 10  Last Interaction   64374 non-null  int64 \n",
      " 11  Churn              64374 non-null  int64 \n",
      "dtypes: int64(9), object(3)\n",
      "memory usage: 5.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Basic data exploration\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e0e2a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values (Example: Fill with mean for numerical features)\n",
    "def preprocess_data(df):\n",
    "    \"\"\"Preprocess the data: handle missing values and encode categorical variables.\"\"\"\n",
    "    # Fill missing values with the mean\n",
    "    df.fillna(df.mean(), inplace=True)\n",
    "    \n",
    "    # One-hot encoding for categorical variables\n",
    "    df = pd.get_dummies(df, columns=['Gender', 'Subscription Type', 'Contract Length'], drop_first=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc842d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CustomerID  Age  Gender  Tenure  Usage Frequency  Support Calls  \\\n",
      "0           1   22  Female      25               14              4   \n",
      "1           2   41  Female      28               28              7   \n",
      "2           3   47    Male      27               10              2   \n",
      "3           4   35    Male       9               12              5   \n",
      "4           5   53  Female      58               24              9   \n",
      "\n",
      "   Payment Delay Subscription Type Contract Length  Total Spend  \\\n",
      "0             27             Basic         Monthly          598   \n",
      "1             13          Standard         Monthly          584   \n",
      "2             29           Premium          Annual          757   \n",
      "3             17           Premium       Quarterly          232   \n",
      "4              2          Standard          Annual          533   \n",
      "\n",
      "   Last Interaction  Churn  \n",
      "0                 9      1  \n",
      "1                20      0  \n",
      "2                21      0  \n",
      "3                18      0  \n",
      "4                18      0  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "576eb22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Names: Index(['CustomerID', 'Age', 'Gender', 'Tenure', 'Usage Frequency',\n",
      "       'Support Calls', 'Payment Delay', 'Subscription Type',\n",
      "       'Contract Length', 'Total Spend', 'Last Interaction', 'Churn'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"Column Names:\", df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f49d717",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stripping Whitespace from Column Names\n",
    "df.columns = df.columns.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "023399bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values:\n",
      " CustomerID           0\n",
      "Age                  0\n",
      "Gender               0\n",
      "Tenure               0\n",
      "Usage Frequency      0\n",
      "Support Calls        0\n",
      "Payment Delay        0\n",
      "Subscription Type    0\n",
      "Contract Length      0\n",
      "Total Spend          0\n",
      "Last Interaction     0\n",
      "Churn                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Checking for Missing Values\n",
    "print(\"Missing values:\\n\", df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c1eb4853",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filling Missing Values\n",
    "df.fillna({\n",
    "    'Total Spend': df['Total Spend'].mean(),\n",
    "    'Support Calls': df['Support Calls'].mean(),\n",
    "    'Payment Delay': df['Payment Delay'].mean(),\n",
    "}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6a7aa3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CustomerID  Age  Gender  Tenure  Usage Frequency  Support Calls  \\\n",
      "0           1   22  Female      25               14              4   \n",
      "1           2   41  Female      28               28              7   \n",
      "2           3   47    Male      27               10              2   \n",
      "3           4   35    Male       9               12              5   \n",
      "4           5   53  Female      58               24              9   \n",
      "\n",
      "   Payment Delay Subscription Type Contract Length  Total Spend  \\\n",
      "0             27             Basic         Monthly          598   \n",
      "1             13          Standard         Monthly          584   \n",
      "2             29           Premium          Annual          757   \n",
      "3             17           Premium       Quarterly          232   \n",
      "4              2          Standard          Annual          533   \n",
      "\n",
      "   Last Interaction  Churn  \n",
      "0                 9      1  \n",
      "1                20      0  \n",
      "2                21      0  \n",
      "3                18      0  \n",
      "4                18      0  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3ad91727",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Date Conversion\n",
    "df['Last Interaction'] = pd.to_datetime(df['Last Interaction'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54be4139",
   "metadata": {},
   "source": [
    "# Feature Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "763338a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Last Interaction  Recency\n",
      "0 1970-01-01 00:00:00.000000009    20023\n",
      "1 1970-01-01 00:00:00.000000020    20023\n",
      "2 1970-01-01 00:00:00.000000021    20023\n",
      "3 1970-01-01 00:00:00.000000018    20023\n",
      "4 1970-01-01 00:00:00.000000018    20023\n"
     ]
    }
   ],
   "source": [
    "df['Recency'] = (pd.to_datetime('now') - df['Last Interaction']).dt.days\n",
    "print(df[['Last Interaction', 'Recency']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2f7f624b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AverageSpend'] = df['Total Spend'] / (df['Tenure'] + 1)  # Avoid division by zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e7009305",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AverageSpend'].replace([np.inf, -np.inf], 0, inplace=True)\n",
    "df['AverageSpend'].fillna(0, inplace=True)  # Fill NaN values with 0 if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2682d55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting Features and Target Variable\n",
    "features = ['Age', 'Gender', 'Tenure', 'Usage Frequency', 'Support Calls', 'Payment Delay', 'Recency', 'AverageSpend']\n",
    "X = df[features]\n",
    "y = df['Churn']  # Assuming Churn is the target variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5882d13a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45061, 8) (19313, 8) (45061,) (19313,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f386f078",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "numeric_features = ['Age', 'Tenure', 'Usage Frequency', 'Support Calls', 'Payment Delay', 'Recency', 'AverageSpend']\n",
    "categorical_features = ['Gender']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(), categorical_features)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f4aaea3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Logistic Regression: {'classifier__C': 1, 'classifier__penalty': 'l2', 'classifier__solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "# Logistic Regression\n",
    "#(citation - reference from analyticsvidhya,greeksfor greeks)\n",
    "logistic_model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# Hyperparameter tuning for Logistic Regression\n",
    "param_grid_logistic = {\n",
    "    'classifier__C': [0.1, 1, 10],\n",
    "    'classifier__solver': ['liblinear', 'saga'],\n",
    "    'classifier__penalty': ['l1', 'l2']\n",
    "}\n",
    "\n",
    "logistic_grid = GridSearchCV(logistic_model, param_grid_logistic, cv=5)\n",
    "logistic_grid.fit(X_train, y_train)\n",
    "\n",
    "# After fitting, you can access best parameters\n",
    "print(\"Best parameters for Logistic Regression:\", logistic_grid.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e9fd46ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.83      0.83     10134\n",
      "           1       0.81      0.83      0.82      9179\n",
      "\n",
      "    accuracy                           0.83     19313\n",
      "   macro avg       0.83      0.83      0.83     19313\n",
      "weighted avg       0.83      0.83      0.83     19313\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_logistic = logistic_grid.predict(X_test)\n",
    "print(\"Logistic Regression Results:\")\n",
    "print(classification_report(y_test, y_pred_logistic))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1bb4a6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Classifier\n",
    "rf_model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier())\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2d7dd028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Random Forest: {'classifier__max_depth': 10, 'classifier__min_samples_split': 5, 'classifier__n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "#Hyperparameter Tuning for Random Forest \n",
    "#(citation : Reference from- chatgpt, geeksforgeeks)\n",
    "param_grid_rf = {\n",
    "    'classifier__n_estimators': [50, 100, 200],\n",
    "    'classifier__max_depth': [None, 10, 20],\n",
    "    'classifier__min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "rf_grid = GridSearchCV(rf_model, param_grid_rf, cv=5)\n",
    "rf_grid.fit(X_train, y_train)\n",
    "print(\"Best parameters for Random Forest:\", rf_grid.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d124c5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97     10134\n",
      "           1       0.94      0.99      0.96      9179\n",
      "\n",
      "    accuracy                           0.97     19313\n",
      "   macro avg       0.97      0.97      0.97     19313\n",
      "weighted avg       0.97      0.97      0.97     19313\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Predictions and Evaluation for Random Forest\n",
    "    y_pred_rf = rf_grid.predict(X_test)\n",
    "print(\"Random Forest Results:\")\n",
    "print(classification_report(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9c7d7cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Logistic Regression: {'classifier__C': 1, 'classifier__penalty': 'l2', 'classifier__solver': 'liblinear'}\n",
      "Best parameters for Random Forest: {'classifier__max_depth': 10, 'classifier__min_samples_split': 5, 'classifier__n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "#Best Parameters Output\n",
    "print(\"Best parameters for Logistic Regression:\", logistic_grid.best_params_)\n",
    "print(\"Best parameters for Random Forest:\", rf_grid.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b9cb8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
